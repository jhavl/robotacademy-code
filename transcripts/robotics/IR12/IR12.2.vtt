WEBVTT
Kind: captions
Language: en-GB

00:00:03.770 --> 00:00:08.900
Peter: I think we all have a fairly hazy idea
about what ethics is. We believe intrinsically

00:00:08.900 --> 00:00:13.920
that ethics is a good thing. My knowledge
of the topic is incredibly limited, so I'd

00:00:13.920 --> 00:00:18.039
like to introduce my colleague professor Doug
Baker, who knows way more about ethics than

00:00:18.039 --> 00:00:19.039
I do. Welcome Doug!

00:00:19.039 --> 00:00:21.280
Doug: Thank you, Peter. A pleasure to be here.

00:00:21.280 --> 00:00:26.700
Peter: So Doug, I don't have a crisp sense
of what ethics is. When I hear the word ethics,

00:00:26.700 --> 00:00:32.520
I think of all kinds of things; right and
wrong, good and evil, morals, values, behaviors.

00:00:32.520 --> 00:00:35.719
Can you untangle some of these things for
me?

00:00:35.719 --> 00:00:43.730
Doug: Yes. I think Peter, when I teach ethics,
I like to first start off with teaching what

00:00:43.730 --> 00:00:44.829
ethics is not.

00:00:44.829 --> 00:00:45.680
Peter: Okay.

00:00:45.680 --> 00:00:49.440
Doug: To start off on the negative, usually
that's not a good thing, but I start off on

00:00:49.440 --> 00:00:57.030
the negative. What it is not; is that it's
not values. It is not religion. It is something

00:00:57.030 --> 00:01:05.500
fundamentally, that underlies all of society,
it underlies all of religion and it transcends culture.

00:01:05.500 --> 00:01:11.280
Peter: So all societies, all religions, all
cultures? It's a global thing?

00:01:11.280 --> 00:01:18.109
Doug: Its global. It is actually the philosophy
of morality and it offers us a guide. Ethics

00:01:18.109 --> 00:01:22.369
offers us a guide as to the right thing to
do.

00:01:22.369 --> 00:01:23.729
Peter: Okay.

00:01:23.729 --> 00:01:33.340
Doug: And so, values are a constellation of
beliefs, an amalgam of who we are, and it's

00:01:33.340 --> 00:01:40.099
culturally specific values and it's contextually
specific. In other words, the values within

00:01:40.099 --> 00:01:47.899
Australian culture in say 1800 are quite different
than the values in Australian culture now.

00:01:47.899 --> 00:01:50.779
Peter: But have ethics changed over the time?

00:01:50.779 --> 00:01:52.679
Doug: No, but values change.

00:01:52.679 --> 00:01:55.039
Peter: So it's an interpretation?

00:01:55.039 --> 00:02:02.989
Doug: Values set the norms of the culture,
and they are a way of enforcing ethics. But

00:02:02.989 --> 00:02:09.050
ethics transcends them, to all cultures as
I said. So, values again are continuous to

00:02:09.050 --> 00:02:15.070
time, but that doesn't change in terms of
ethics. What ought to be the right thing to

00:02:15.070 --> 00:02:19.780
do, what is the right thing to do is determined
by moral reasoning.

00:02:19.780 --> 00:02:25.260
Peter: So people have been thinking about
ethics for a long, long time, maybe the longest

00:02:25.260 --> 00:02:29.950
activity or topic that people have thought
about. Do they all agree?

00:02:29.950 --> 00:02:37.610
Doug: No. But, listen, there are degrees in
ethical theory. It is a huge area and in terms

00:02:37.610 --> 00:02:43.150
of how we proceed ethically, there's generally
two different schools of thought. There's

00:02:43.150 --> 00:02:50.220
teleology and there's deontology, and if we
look at those two different schools of thought

00:02:50.220 --> 00:02:55.740
in terms of moral reasoning, they'd come to
how we should proceed and how we ought to

00:02:55.740 --> 00:02:56.790
act differently.

00:02:56.790 --> 00:02:59.500
Peter: Okay so run me through these two.

00:02:59.500 --> 00:03:09.080
Doug: Okay. So first teleology looks at the
good thing, the right thing to do; what's

00:03:09.080 --> 00:03:16.290
good in the end, and it looks at the process
of getting what's good, and the argument with

00:03:16.290 --> 00:03:23.790
teleology is, we proceed into the future by
doing the right thing and producing the greatest

00:03:23.790 --> 00:03:31.080
good. And so, the argument in it is, it's
not the process but the product, and it's

00:03:31.080 --> 00:03:37.390
also called consequentialism. And in terms
of the utilitarians Bentham and Mill in the

00:03:37.390 --> 00:03:46.340
1840's, 1850's and 1860's, utilitarianism
is brought in this branch of ethics by looking

00:03:46.340 --> 00:03:52.819
at the greatest good for the greatest number.
So, whatever you do should build the largest

00:03:52.819 --> 00:03:56.390
degree of happiness, so the end result is
what comes.

00:03:56.390 --> 00:03:59.319
Peter: So it's not about the individual, it's
about the greater good?

00:03:59.319 --> 00:03:59.720
Doug: Correct.

00:03:59.720 --> 00:04:00.120
Peter: Okay.

00:04:00.120 --> 00:04:08.380
Doug: Yeah, exactly right. So, if we build
a dam for power, the objective is to build

00:04:08.380 --> 00:04:16.590
an industrial reservoir for power for the
industrialisation of a nation, and the fact

00:04:16.590 --> 00:04:22.699
that we have to move out two hundred farmers
or a couple of villagers doesn't matter.

00:04:22.699 --> 00:04:24.340
Peter: Because of the greater good?

00:04:24.340 --> 00:04:25.400
Doug: It's what counts.

00:04:25.400 --> 00:04:30.080
Peter: Okay. So, in an engineering term then,
you'd say that would depend on your cost function.

00:04:30.080 --> 00:04:35.340
It would depend on the weights that you applied
to electricity and to the happiness of the village.

00:04:35.349 --> 00:04:40.240
Doug: Absolutely. And so, it becomes a case
of measuring market and non market variables.

00:04:40.240 --> 00:04:44.499
But the greatest good for the greatest number
is often the argument you see in a lot of

00:04:44.499 --> 00:04:48.919
mega projects. That, yeah we know, we know
we have to affect you here and we know this

00:04:48.919 --> 00:04:53.639
community's getting impacted but, for the
greater number, it's important.

00:04:53.639 --> 00:04:55.629
Peter: Tell me about the other branch.

00:04:55.629 --> 00:05:08.479
Doug: The other branch really looks at the
process. Deontology is a whole area of thought,

00:05:08.479 --> 00:05:15.620
starting with can't and moving forward right
through the rolls, that looks at the process,

00:05:15.620 --> 00:05:21.990
and the argument is that the process and the
good are separated. So what is good is separate

00:05:21.990 --> 00:05:24.379
from the correctness of the process.

00:05:24.379 --> 00:05:25.509
Peter: It's how you get there?

00:05:25.509 --> 00:05:25.999
Doug: Correct.

00:05:25.999 --> 00:05:26.419
Peter: Okay

00:05:26.419 --> 00:05:35.020
Doug: So the argument is in fact how we do
it, it's critical, and that moral guidance

00:05:35.020 --> 00:05:37.909
as to how we do it makes the difference.

00:05:37.909 --> 00:05:39.439
Peter: Can you give me an example.

00:05:39.439 --> 00:05:47.110
Doug: So in terms of public participation,
the argument is, for example, any government

00:05:47.110 --> 00:05:54.330
would actually, when they have a large project
in their mind go ahead and do it in the past.

00:05:54.330 --> 00:06:00.110
But now we have a process by which to inform
the public, to integrate the public, to make

00:06:00.110 --> 00:06:04.830
the decisions as to whether this is the best
path to go, and more people are involved in

00:06:04.830 --> 00:06:09.680
the decision making process, and as a result
public participation and stakeholder participation

00:06:09.680 --> 00:06:17.860
is bloomed as a result of this. But the key
with this branch - deontology; John Rawls

00:06:17.860 --> 00:06:24.559
is probably the most well known philosopher
of the 20th Century, really looked at a theory

00:06:24.559 --> 00:06:29.319
of justice, and the argument was, what counts
here is justice for the individual, and we

00:06:29.319 --> 00:06:33.400
base our decisions on what's right for the
individual and not to harm the individual.

00:06:33.400 --> 00:06:38.749
Peter: Okay so one branch then is the greater
good of however we might define that, other

00:06:38.749 --> 00:06:41.309
branch is what's best for the individual.

00:06:41.309 --> 00:06:42.069
Doug: Absolutely.

00:06:42.069 --> 00:06:48.719
Peter: So I can pick and choose? No one of
both ethics is better than the other?

00:06:48.719 --> 00:06:53.139
Doug: Correct. And you can justify it accordingly.
For example, in consequentialism when you

00:06:53.139 --> 00:07:02.210
look at positive discrimination, in other
words a preferential hiring of say, first

00:07:02.210 --> 00:07:08.819
nations or aboriginal people over top of other
applicants, or the hiring of women over the

00:07:08.819 --> 00:07:15.639
top of men, in preference to men. Now the
argument is that positive discrimination is

00:07:15.639 --> 00:07:23.059
justified in a consequentialist argument,
in that there has been problems in the past

00:07:23.059 --> 00:07:29.319
with respect to how we treated women and how
we fired. We can rectify that in the present

00:07:29.319 --> 00:07:36.119
by specifically focusing on hiring them and
violating the principle of justice, but the

00:07:36.119 --> 00:07:39.099
end result is that we'll have 50% women in
the work place.

00:07:39.099 --> 00:07:39.639
Peter: Yeah.

00:07:39.639 --> 00:07:43.819
Doug: You're with me? So that's a consequentialist
argument. Now a deontologist would take offence

00:07:43.819 --> 00:07:50.919
to that, because you're violating fairness.
And so, a consequentialist's perspective then

00:07:50.919 --> 00:07:58.519
has the end result in mind, and again the greater good in mind. So you can argue from both sides.

00:07:58.520 --> 00:08:03.699
Peter: So Doug, given all of that, how do
I put ethical thinking into practice?

00:08:03.699 --> 00:08:10.369
Doug: There's no formula but there's a fundamental
kind of basis for all moral codes.

00:08:10.369 --> 00:08:11.349
Peter: Okay.

00:08:11.349 --> 00:08:18.860
Doug: It hinges around again, the individual
and the rights of the individual. First there's

00:08:18.860 --> 00:08:25.189
the construct of autonomy - the right of the
individual to make their own choice and not

00:08:25.189 --> 00:08:31.169
to violate that. Secondly, there's a construct
of maleficence - to do no harm.

00:08:31.169 --> 00:08:32.039
Peter: Okay.

00:08:32.039 --> 00:08:38.350
Doug: And it's the ethical code that surrounds
doctors. It's formed around non-maleficence.

00:08:38.350 --> 00:08:45.040
Then there's beneficence, which is to help,
to aid. Secondly, or lastly, there's this

00:08:45.040 --> 00:08:51.960
notion of justice and that's Rawls approach. You must have fairness. The fairness principle is critical.

00:08:51.960 --> 00:08:54.600
Peter: Is fairness an absolute concept?

00:08:54.600 --> 00:09:00.350
Doug: Yes, it is. And it can be weighed if
you look at the utilitarian theory and Pareto

00:09:00.350 --> 00:09:07.330
economics - they lay fairness in that construct,
in terms of what is fair and what isn't and

00:09:07.330 --> 00:09:13.930
how do we determine fairness. So, it translates,
much of this ethical theory translates directly

00:09:13.930 --> 00:09:18.810
into economic theory and utilitarian theory.
So it's fascinating how it's all brought in

00:09:18.810 --> 00:09:22.700
and through it into the how we see the world
and how we evaluate the world.

00:09:22.700 --> 00:09:27.380
Peter: So it's not just some abstract notion,
it can be put into practice and it underpins

00:09:27.380 --> 00:09:29.800
really important things in our society.

00:09:29.800 --> 00:09:34.580
Doug: Absolutely! There's nothing more applied
than a good ethical theory.

